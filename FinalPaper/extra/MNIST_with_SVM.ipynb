{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-78Lo2pOPEms",
        "outputId": "7e845546-980d-4b8a-9e3b-39c896dac4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "# Extracting features and labels\n",
        "X, y = mnist['data'], mnist['target']\n",
        "\n",
        "# Convert X to a NumPy array\n",
        "X = np.array(X)\n",
        "\n",
        "# Preprocess the data\n",
        "# Normalization\n",
        "X = X / 255.0\n",
        "# Flattening\n",
        "X_flat = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Implementing a supervised learning algorithm (Support Vector Machine)\n",
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluating the classification model's performance\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
        "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
        "print(\"Supervised Learning (Support Vector Machine) Performance Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "print(\"Precision:\", precision_svm)\n",
        "print(\"Recall:\", recall_svm)\n",
        "\n",
        "# Provide comments and explanations\n",
        "# MNIST dataset is loaded and preprocessed by normalizing pixel values and flattening the images.\n",
        "# The dataset is split into training and testing sets.\n",
        "# A supervised learning algorithm, Support Vector Machine (SVM), is implemented and trained on the training data.\n",
        "# The performance of the model is evaluated using accuracy, precision, and recall metrics.\n"
      ]
    }
  ]
}