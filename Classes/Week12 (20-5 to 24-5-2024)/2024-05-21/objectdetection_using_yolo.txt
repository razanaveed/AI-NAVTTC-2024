from ultralytics import YOLO
import cv2
import math
from google.colab.patches import cv2_imshow
from pytube import YouTube

# Function to get the stream URL
def get_stream_url(youtube_url):
    yt = YouTube(youtube_url)
    stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()
    return stream.url

# URL of the YouTube video
youtube_url = 'https://www.youtube.com/watch?v=3kO21UGpCNw'

# Get the direct video stream URL
video_url = get_stream_url(youtube_url)

# Open the video stream
cap = cv2.VideoCapture(video_url)

# Check if the video stream is opened successfully
if not cap.isOpened():
    print("Error: Could not open video stream.")
    exit()

# Model
model = YOLO("yolo-Weights/yolov8n.pt")  # Ensure the weights file is accessible in the Colab environment

# Object classes
classNames = ["person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella",
              "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
              "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup",
              "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli",
              "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa", "pottedplant", "bed",
              "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard", "cell phone",
              "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
              "teddy bear", "hair drier", "toothbrush"]

# Get video properties
fps = cap.get(cv2.CAP_PROP_FPS)
frame_skip = int(fps)  # Number of frames to skip to process at 1-second intervals

# Output video file
output_path = "output_video.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec
frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
out = cv2.VideoWriter(output_path, fourcc, fps, frame_size)

frame_count = 0

while cap.isOpened():
    success, img = cap.read()

    if not success:
        break

    # Skip frames
    if frame_count % frame_skip == 0:
        # Perform object detection
        results = model(img, stream=True)

        # Process the results
        for r in results:
            boxes = r.boxes

            for box in boxes:
                # Bounding box
                x1, y1, x2, y2 = box.xyxy[0]
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convert to int values

                # Draw bounding box
                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)

                # Confidence
                confidence = math.ceil((box.conf[0] * 100)) / 100
                print("Confidence --->", confidence)

                # Class name
                cls = int(box.cls[0])
                print("Class name -->", classNames[cls])

                # Draw class name and confidence
                label = f"{classNames[cls]}: {confidence:.2f}"
                cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        # Show the frame
        cv2_imshow(img)

        # Write the frame to the output video
        out.write(img)

    frame_count += 1

# Release resources
cap.release()
out.release()
cv2.destroyAllWindows()

# Download the video
from google.colab import files
files.download(output_path)