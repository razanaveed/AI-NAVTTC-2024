{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xUyQMDxSaPn"
   },
   "source": [
    "Pandas is one of the most widely used Python libraries for data manipulation and analysis. It provides high-performance, easy-to-use data structures and data analysis tools for Python programming. If you're working with tabular data, Pandas is an indispensable tool that simplifies data loading, manipulation, and analysis tasks.\n",
    "\n",
    "Here's a brief introduction to some of the key components and concepts in Pandas:\n",
    "\n",
    "1. **Data Structures**:\n",
    "   - **Series**: A one-dimensional labeled array capable of holding any data type. It is like a column in a spreadsheet or a SQL table.\n",
    "   - **DataFrame**: A two-dimensional labeled data structure with columns of potentially different types. It is like a spreadsheet or SQL table, where each column is a Series.\n",
    "\n",
    "2. **Key Features**:\n",
    "   - Data alignment and handling missing data.\n",
    "   - Reshaping and pivoting datasets.\n",
    "   - Label-based slicing, indexing, and subsetting of large datasets.\n",
    "   - Database-like operations such as merging and joining datasets.\n",
    "   - Time-series functionality.\n",
    "   - Powerful I/O tools for reading and writing data from and to various file formats like CSV, Excel, SQL databases, etc.\n",
    "\n",
    "3. **Basic Operations**:\n",
    "   - **Loading Data**: Pandas provides functions to read data from various file formats like CSV, Excel, JSON, SQL databases, etc., into DataFrame objects.\n",
    "   - **Viewing Data**: You can use functions like `head()`, `tail()`, and `sample()` to quickly view the first few, last few, or random rows of a DataFrame.\n",
    "   - **Selecting and Filtering Data**: You can use boolean indexing, label-based indexing, or positional indexing to select subsets of data.\n",
    "   - **Manipulating Data**: Pandas provides functions for tasks like adding or removing columns, applying functions element-wise, grouping data, and aggregating data.\n",
    "   - **Handling Missing Data**: Pandas provides methods to detect, remove, or replace missing values in datasets.\n",
    "   - **Visualizing Data**: Although Pandas itself doesn't provide visualization capabilities, it seamlessly integrates with libraries like Matplotlib and Seaborn for data visualization.\n",
    "\n",
    "4. **Common Use Cases**:\n",
    "   - Data cleaning and preprocessing.\n",
    "   - Exploratory data analysis (EDA).\n",
    "   - Time series analysis.\n",
    "   - Statistical analysis.\n",
    "   - Data wrangling and transformation.\n",
    "   - Data aggregation and summarization.\n",
    "\n",
    "5. **Integration with Other Libraries**:\n",
    "   - Pandas works well with other Python libraries commonly used in the data science ecosystem, such as NumPy, Matplotlib, SciPy, and Scikit-learn.\n",
    "\n",
    "To start using Pandas, you need to have it installed in your Python environment. You can install it using pip:\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "Once installed, you can import it into your Python scripts or Jupyter Notebooks using:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "This imports Pandas with the alias `pd`, which is a common convention in the Python community. Now you can start exploring and manipulating your data using Pandas' powerful functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOI4q1tJSvp-"
   },
   "source": [
    "Let's delve deeper into Series, DataFrame, and various data input methods in Pandas, as well as how to perform selection and indexing operations:\n",
    "\n",
    "### Series and DataFrame:\n",
    "\n",
    "1. **Series**:\n",
    "   - A Series is a one-dimensional labeled array capable of holding any data type.\n",
    "   - It can be created from a list, NumPy array, or dictionary.\n",
    "   - Each element in the Series has an associated index label.\n",
    "\n",
    "Example of creating a Series:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# From a list\n",
    "s = pd.Series([1, 3, 5, 7, 9])\n",
    "print(s)\n",
    "\n",
    "# From a dictionary\n",
    "data = {'a': 0, 'b': 1, 'c': 2}\n",
    "s = pd.Series(data)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "2. **DataFrame**:\n",
    "   - A DataFrame is a two-dimensional labeled data structure with columns of potentially different types.\n",
    "   - It can be thought of as a spreadsheet or SQL table.\n",
    "   - Each column in a DataFrame is a Series.\n",
    "\n",
    "Example of creating a DataFrame:\n",
    "```python\n",
    "# From a dictionary\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# From a list of dictionaries\n",
    "data = [{'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
    "        {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'},\n",
    "        {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "### Data Input:\n",
    "\n",
    "Pandas provides various methods to read data from different file formats into DataFrame objects. Some common methods include:\n",
    "\n",
    "1. **CSV**:\n",
    "```python\n",
    "df = pd.read_csv('data.csv')\n",
    "```\n",
    "\n",
    "2. **Excel**:\n",
    "```python\n",
    "df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "```\n",
    "\n",
    "3. **JSON**:\n",
    "```python\n",
    "df = pd.read_json('data.json')\n",
    "```\n",
    "\n",
    "4. **SQL Database**:\n",
    "```python\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "query = \"SELECT * FROM table_name;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "```\n",
    "\n",
    "### Selection and Indexing:\n",
    "\n",
    "Pandas provides various methods for selecting and indexing data in Series and DataFrame objects.\n",
    "\n",
    "1. **Selection by Label**:\n",
    "```python\n",
    "# Selecting a single column\n",
    "column = df['Column_Name']\n",
    "\n",
    "# Selecting multiple columns\n",
    "subset = df[['Column1', 'Column2']]\n",
    "\n",
    "# Selecting rows by label\n",
    "row = df.loc[row_label]\n",
    "\n",
    "# Selecting rows and columns by label\n",
    "subset = df.loc[row_label, column_label]\n",
    "```\n",
    "\n",
    "2. **Selection by Position**:\n",
    "```python\n",
    "# Selecting a single row\n",
    "row = df.iloc[row_index]\n",
    "\n",
    "# Selecting a subset of rows and columns by position\n",
    "subset = df.iloc[row_start:row_end, col_start:col_end]\n",
    "```\n",
    "\n",
    "3. **Conditional Selection**:\n",
    "```python\n",
    "# Selecting rows based on a condition\n",
    "subset = df[df['Column'] > value]\n",
    "\n",
    "# Selecting rows based on multiple conditions\n",
    "subset = df[(df['Column1'] > value1) & (df['Column2'] == value2)]\n",
    "```\n",
    "\n",
    "4. **Index Setting**:\n",
    "```python\n",
    "# Setting a column as the index\n",
    "df.set_index('Column_Name', inplace=True)\n",
    "\n",
    "# Resetting the index\n",
    "df.reset_index(inplace=True)\n",
    "```\n",
    "\n",
    "These are some of the basic operations for working with Series and DataFrame objects in Pandas, as well as reading data and performing selection and indexing operations. Pandas provides extensive functionality for data manipulation, exploration, and analysis beyond these basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VFXuC34S_Hc"
   },
   "source": [
    "\n",
    "\n",
    "1. **head()**: Returns the first n rows of the DataFrame.\n",
    "```python\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "2. **unique()**: Returns unique values in a column.\n",
    "```python\n",
    "unique_values = df['Column_Name'].unique()\n",
    "```\n",
    "\n",
    "3. **value_counts()**: Returns the frequency of unique values in a column.\n",
    "```python\n",
    "value_counts = df['Column_Name'].value_counts()\n",
    "```\n",
    "\n",
    "4. **Applying Custom Functions**: You can apply custom functions using `apply()` or `applymap()` methods.\n",
    "```python\n",
    "def custom_function(x):\n",
    "    return x * 2\n",
    "\n",
    "df['New_Column'] = df['Existing_Column'].apply(custom_function)\n",
    "```\n",
    "\n",
    "5. **Getting Column and Index Names**:\n",
    "```python\n",
    "column_names = df.columns\n",
    "index_names = df.index\n",
    "```\n",
    "\n",
    "6. **Sorting and Ordering**:\n",
    "```python\n",
    "# Sorting by values in a column\n",
    "df_sorted = df.sort_values(by='Column_Name')\n",
    "\n",
    "# Sorting by index\n",
    "df_sorted = df.sort_index()\n",
    "```\n",
    "\n",
    "7. **Null Value Check**:\n",
    "```python\n",
    "# Check for null values in the DataFrame\n",
    "null_check = df.isnull()\n",
    "\n",
    "# Check for null values in a specific column\n",
    "null_check_column = df['Column_Name'].isnull()\n",
    "```\n",
    "\n",
    "8. **Value Replacement**:\n",
    "```python\n",
    "# Replace specific values in a column\n",
    "df['Column_Name'].replace({old_value: new_value}, inplace=True)\n",
    "```\n",
    "\n",
    "9. **Dropping Rows and Columns**:\n",
    "```python\n",
    "# Drop rows with null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns=['Column1', 'Column2'], inplace=True)\n",
    "```\n",
    "\n",
    "These are some common operations you can perform on Pandas DataFrames. Pandas offers a wide range of functions and methods for data manipulation and analysis, making it a powerful tool for working with tabular data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx6ElaqZTKSs"
   },
   "source": [
    "Handling missing data is a crucial aspect of data analysis and manipulation. Pandas provides several methods to detect, remove, or replace missing values in DataFrames. Here's how you can handle missing data using Pandas:\n",
    "\n",
    "1. **Detecting Missing Data**:\n",
    "   - `isnull()`: Returns a DataFrame of the same shape as the input with True where NaN values are present, and False where they are not.\n",
    "   - `notnull()`: Returns the inverse of `isnull()`, i.e., True where values are not NaN, and False where they are NaN.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Check for missing values\n",
    "missing_values = df.isnull()\n",
    "\n",
    "# Check for non-missing values\n",
    "non_missing_values = df.notnull()\n",
    "```\n",
    "\n",
    "2. **Removing Missing Data**:\n",
    "   - `dropna()`: Removes rows or columns with missing values.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove columns with missing values\n",
    "df.dropna(axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "3. **Replacing Missing Data**:\n",
    "   - `fillna()`: Fills missing values with a specified value or a computed value like mean, median, or mode.\n",
    "   - `interpolate()`: Interpolates missing values based on different methods like linear, quadratic, etc.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Replace missing values with a specified value\n",
    "df.fillna(value=0, inplace=True)\n",
    "\n",
    "# Replace missing values with the mean of the column\n",
    "mean = df['Column_Name'].mean()\n",
    "df['Column_Name'].fillna(value=mean, inplace=True)\n",
    "\n",
    "# Interpolate missing values\n",
    "df['Column_Name'].interpolate(method='linear', inplace=True)\n",
    "```\n",
    "\n",
    "4. **Handling Missing Data during Data Input**:\n",
    "   Pandas provides parameters in its read functions to handle missing values during data input.\n",
    "   - `na_values`: Specifies additional strings to recognize as NaN.\n",
    "   - `keep_default_na`: Specifies whether to keep the default NaN values like 'NaN', 'NULL', etc.\n",
    "   - `na_filter`: Specifies whether to detect missing values.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Read CSV with custom NaN values\n",
    "df = pd.read_csv('data.csv', na_values=['-1', '999'])\n",
    "\n",
    "# Read CSV without detecting missing values\n",
    "df = pd.read_csv('data.csv', na_filter=False)\n",
    "```\n",
    "\n",
    "By utilizing these methods, you can effectively handle missing data in your Pandas DataFrames, ensuring that your analysis is robust and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WC-jRCvTezz"
   },
   "source": [
    "In Pandas, you can combine datasets through merging, joining, and concatenation. These operations allow you to combine data from different DataFrames based on common columns or indices. Here's how you can perform merging, joining, and concatenation in Pandas:\n",
    "\n",
    "### Concatenation:\n",
    "\n",
    "Concatenation is the process of combining DataFrames along a particular axis, either along rows or columns.\n",
    "\n",
    "- **`pd.concat()`**: Concatenates DataFrames along a specified axis.\n",
    "\n",
    "```python\n",
    "result = pd.concat([df1, df2])  # Concatenate along rows (axis=0)\n",
    "result = pd.concat([df1, df2], axis=1)  # Concatenate along columns (axis=1)\n",
    "```\n",
    "\n",
    "### Merging:\n",
    "\n",
    "Merging allows you to combine DataFrames based on the values of one or more keys.\n",
    "\n",
    "- **`pd.merge()`**: Merges DataFrames using a database-style join.\n",
    "\n",
    "```python\n",
    "result = pd.merge(df1, df2, on='key_column')  # Inner join on a single key\n",
    "result = pd.merge(df1, df2, on=['key_column1', 'key_column2'])  # Inner join on multiple keys\n",
    "```\n",
    "\n",
    "### Joining:\n",
    "\n",
    "Joining is similar to merging, but it merges DataFrames on their indices rather than on columns.\n",
    "\n",
    "- **`DataFrame.join()`**: Joins DataFrames based on their indices.\n",
    "\n",
    "```python\n",
    "result = df1.join(df2, how='inner')  # Inner join based on index\n",
    "```\n",
    "\n",
    "### Types of Joins:\n",
    "\n",
    "When merging DataFrames, you can specify different types of joins:\n",
    "\n",
    "- **Inner Join** (default behavior):\n",
    "  - Keeps only the common values in both DataFrames.\n",
    "\n",
    "- **Outer Join**:\n",
    "  - Keeps all values from both DataFrames and fills in missing values with NaN.\n",
    "\n",
    "- **Left Join**:\n",
    "  - Keeps all values from the left DataFrame and fills in missing values with NaN for the right DataFrame.\n",
    "\n",
    "- **Right Join**:\n",
    "  - Keeps all values from the right DataFrame and fills in missing values with NaN for the left DataFrame.\n",
    "\n",
    "You can specify the type of join using the `how` parameter in `pd.merge()` or `DataFrame.join()`.\n",
    "\n",
    "```python\n",
    "# Example of different types of joins\n",
    "inner_join = pd.merge(df1, df2, how='inner')\n",
    "outer_join = pd.merge(df1, df2, how='outer')\n",
    "left_join = pd.merge(df1, df2, how='left')\n",
    "right_join = pd.merge(df1, df2, how='right')\n",
    "```\n",
    "\n",
    "These operations provide flexibility in combining datasets in Pandas, allowing you to perform various types of merges and concatenations based on your specific requirements and the structure of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE6cLffwTgBz"
   },
   "source": [
    "### GroupBy:\n",
    "\n",
    "GroupBy operation involves splitting the data into groups based on some criteria, applying a function to each group independently, and then combining the results into a DataFrame.\n",
    "\n",
    "- **`groupby()`**: Groups DataFrame using a mapper or by a Series of columns.\n",
    "- **Aggregation Functions**: Functions like `sum()`, `mean()`, `count()`, `min()`, `max()`, etc., can be applied to grouped data.\n",
    "- **Transformation Functions**: Functions like `transform()` can be applied to perform group-wise operations that return an object that is indexed the same size as the group.\n",
    "\n",
    "```python\n",
    "# Grouping by a column and applying aggregation functions\n",
    "grouped_data = df.groupby('Column_Name')\n",
    "sums = grouped_data.sum()\n",
    "means = grouped_data.mean()\n",
    "counts = grouped_data.size()\n",
    "\n",
    "# Grouping by multiple columns and applying aggregation functions\n",
    "multi_grouped_data = df.groupby(['Column1', 'Column2'])\n",
    "```\n",
    "\n",
    "### Discretization and Binning:\n",
    "\n",
    "Discretization involves converting continuous data into discrete bins or categories.\n",
    "\n",
    "- **`pd.cut()`**: Discretizes continuous data into intervals.\n",
    "- **`pd.qcut()`**: Discretizes continuous data into quantiles.\n",
    "\n",
    "```python\n",
    "# Discretization using cut\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "df['Binned_Column'] = pd.cut(df['Numeric_Column'], bins=bins, labels=labels)\n",
    "\n",
    "# Discretization using qcut\n",
    "df['Quantile_Binned_Column'] = pd.qcut(df['Numeric_Column'], q=4)  # Quartiles\n",
    "```\n",
    "\n",
    "### Operations on DataFrames:\n",
    "\n",
    "Pandas provides various operations for data manipulation and analysis on DataFrames.\n",
    "\n",
    "- **Arithmetic Operations**: You can perform arithmetic operations element-wise or between DataFrames.\n",
    "```python\n",
    "# Element-wise addition\n",
    "result = df1 + df2\n",
    "\n",
    "# Addition of DataFrames with different dimensions (broadcasting)\n",
    "result = df1 + scalar_value\n",
    "```\n",
    "\n",
    "- **Statistical Operations**: Pandas provides statistical functions like `mean()`, `median()`, `std()`, `var()`, etc., to compute summary statistics.\n",
    "```python\n",
    "# Calculate mean\n",
    "mean = df.mean()\n",
    "\n",
    "# Calculate median\n",
    "median = df.median()\n",
    "```\n",
    "\n",
    "- **Applying Functions**: You can apply custom functions using `apply()` or `applymap()` methods.\n",
    "```python\n",
    "# Apply function to each column\n",
    "result = df.apply(custom_function)\n",
    "\n",
    "# Apply function element-wise\n",
    "result = df.applymap(custom_function)\n",
    "```\n",
    "\n",
    "- **Sorting DataFrames**:\n",
    "```python\n",
    "# Sorting by values in a column\n",
    "df_sorted = df.sort_values(by='Column_Name')\n",
    "\n",
    "# Sorting by index\n",
    "df_sorted = df.sort_index()\n",
    "```\n",
    "\n",
    "- **Null Value Check**:\n",
    "```python\n",
    "# Check for null values in the DataFrame\n",
    "null_check = df.isnull()\n",
    "\n",
    "# Check for null values in a specific column\n",
    "null_check_column = df['Column_Name'].isnull()\n",
    "```\n",
    "\n",
    "These are some common operations you can perform on DataFrames in Pandas, including GroupBy operations, Discretization and Binning, and various operations like arithmetic, statistical, applying functions, sorting, and null value check. These operations make Pandas a powerful tool for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5V14wm8Tr-s"
   },
   "source": [
    "Certainly! Let's explore data output/saving in Pandas and how you can use Pandas for plotting with various types of plots:\n",
    "\n",
    "### Data Output/Saving:\n",
    "\n",
    "Pandas provides methods to save DataFrame objects to various file formats.\n",
    "\n",
    "- **`to_csv()`**: Saves DataFrame to a CSV file.\n",
    "```python\n",
    "df.to_csv('data.csv', index=False)  # Specify index=False to exclude index from the output\n",
    "```\n",
    "\n",
    "- **`to_excel()`**: Saves DataFrame to an Excel file.\n",
    "```python\n",
    "df.to_excel('data.xlsx', index=False)\n",
    "```\n",
    "\n",
    "- **`to_json()`**: Saves DataFrame to a JSON file.\n",
    "```python\n",
    "df.to_json('data.json', orient='records')  # Specify orient='records' to save as a JSON array\n",
    "```\n",
    "\n",
    "- **`to_sql()`**: Saves DataFrame to a SQL database.\n",
    "```python\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "df.to_sql('table_name', conn, index=False)\n",
    "```\n",
    "\n",
    "### Pandas for Plotting:\n",
    "\n",
    "Pandas provides a convenient interface to Matplotlib for creating various types of plots directly from DataFrame objects.\n",
    "\n",
    "- **Area Plot**:\n",
    "```python\n",
    "df.plot.area()\n",
    "```\n",
    "\n",
    "- **Bar Plot**:\n",
    "```python\n",
    "df.plot.bar()\n",
    "```\n",
    "\n",
    "- **Density Plot**:\n",
    "```python\n",
    "df.plot.density()\n",
    "```\n",
    "\n",
    "- **Histogram**:\n",
    "```python\n",
    "df.plot.hist()\n",
    "```\n",
    "\n",
    "- **Line Plot**:\n",
    "```python\n",
    "df.plot.line()\n",
    "```\n",
    "\n",
    "- **Scatter Plot**:\n",
    "```python\n",
    "df.plot.scatter(x='Column1', y='Column2')\n",
    "```\n",
    "\n",
    "- **Horizontal Bar Plot**:\n",
    "```python\n",
    "df.plot.barh()\n",
    "```\n",
    "\n",
    "- **Box Plot**:\n",
    "```python\n",
    "df.plot.box()\n",
    "```\n",
    "\n",
    "- **Hexbin Plot**:\n",
    "```python\n",
    "df.plot.hexbin(x='Column1', y='Column2', gridsize=20)\n",
    "```\n",
    "\n",
    "- **KDE Plot**:\n",
    "```python\n",
    "df.plot.kde()\n",
    "```\n",
    "\n",
    "- **Pie Plot**:\n",
    "```python\n",
    "df['Column'].value_counts().plot.pie()\n",
    "```\n",
    "\n",
    "Each of these plot functions can take various parameters to customize the appearance of the plots, such as colors, labels, titles, etc. Additionally, you can also use Matplotlib directly for more advanced customization if needed.\n",
    "\n",
    "These functionalities make Pandas a powerful tool not only for data manipulation and analysis but also for data visualization and exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwFS9jvcToXk"
   },
   "source": [
    "To create basic plots using data stored in a DataFrame in Python, you can use libraries such as Matplotlib or Seaborn. Here's a simple example using Matplotlib:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Year': [2015, 2016, 2017, 2018, 2019],\n",
    "    'Revenue': [10000, 15000, 20000, 25000, 30000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df['Year'], df['Revenue'], marker='o', linestyle='-')\n",
    "plt.title('Revenue Over Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This code will generate a simple line plot showing the revenue over the years.\n",
    "\n",
    "If you prefer using Seaborn, which provides more aesthetically pleasing default styles and a higher-level interface for drawing attractive and informative statistical graphics, you can do something like this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Year': [2015, 2016, 2017, 2018, 2019],\n",
    "    'Revenue': [10000, 15000, 20000, 25000, 30000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=df, x='Year', y='Revenue', marker='o')\n",
    "plt.title('Revenue Over Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This code produces the same plot as before but using Seaborn's lineplot function. Seaborn also provides various additional options for customizing the appearance of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzXrxjFbKJgE"
   },
   "source": [
    "Sure! Below are examples of various types of plots you can create using data stored in a DataFrame in Python, using Matplotlib and Seaborn:\n",
    "\n",
    "1. **Line Plot**: Shows data points connected by straight lines.\n",
    "   \n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Year': [2015, 2016, 2017, 2018, 2019],\n",
    "        'Revenue': [10000, 15000, 20000, 25000, 30000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Line plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df['Year'], df['Revenue'], marker='o', linestyle='-')\n",
    "plt.title('Revenue Over Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "2. **Bar Plot**: Represents categorical data with rectangular bars.\n",
    "\n",
    "```python\n",
    "# Bar plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(df['Year'], df['Revenue'], color='skyblue')\n",
    "plt.title('Revenue by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "3. **Histogram**: Displays the distribution of a numerical variable.\n",
    "\n",
    "```python\n",
    "# Histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['Revenue'], bins=5, color='lightgreen', edgecolor='black')\n",
    "plt.title('Revenue Distribution')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "4. **Scatter Plot**: Represents data points on a two-dimensional plane.\n",
    "\n",
    "```python\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(df['Year'], df['Revenue'], color='orange', marker='o')\n",
    "plt.title('Revenue vs. Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "5. **Box Plot**: Summarizes the distribution of a numerical variable.\n",
    "\n",
    "```python\n",
    "# Box plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.boxplot(df['Revenue'], vert=False)\n",
    "plt.title('Revenue Box Plot')\n",
    "plt.xlabel('Revenue')\n",
    "plt.yticks([])\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "6. **Violin Plot**: Shows the distribution of the data and its probability density.\n",
    "\n",
    "```python\n",
    "# Violin plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.violinplot(data=df, y='Revenue', color='lightblue')\n",
    "plt.title('Revenue Violin Plot')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "These are just a few examples. Depending on your data and the story you want to tell, you may choose different types of plots or further customize these plots to suit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRJVRmIqKUfy"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
